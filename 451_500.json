[
  {
    "id": 1451,
    "q": "A major finance organisation has engaged your company to set up a large data mining application. Using AWS you decide the best service for this is Amazon Elastic MapReduce (EMR) which you know uses Hadoop. Which of the following statements best describes Hadoop?",
    "o": [
      {
        "c": "Hadoop is 3rd Party software which can be installed using AMI.",
        "a": "no"
      },
      {
        "c": "Hadoop is an open source python web framework.",
        "a": "no"
      },
      {
        "c": "Hadoop is an open source Java software framework.",
        "a": "yes"
      },
      {
        "c": "Hadoop is an open source javascript framework.",
        "a": "no"
      }
    ],
    "nt": "Hadoop is an open-source software framework written in Java that allows for the distributed processing of large data sets across clusters of computers using simple programming models. It is designed to scale up from single servers to thousands of machines, each offering local computation and storage."
  },
  {
    "id": 1452,
    "q": "A customer has established an AWS Direct Connect connection to AWS. The link is up and routes are being advertised from the customer's end, however the customer is unable to connect from EC2 instances inside its VPC to servers residing in its datacenter. Which of the following options provide a viable solution to remedy this situation? (Choose 2 answers)",
    "o": [
      {
        "c": "Add a route to the route table with an IPsec VPN connection as the target.",
        "a": "no"
      },
      {
        "c": "Enable route propagation to the virtual pinnate gateway (VGW).",
        "a": "yes"
      },
      {
        "c": "Enable route propagation to the customer gateway (CGW).",
        "a": "no"
      },
      {
        "c": "Modify the route table of all Instances using the 'route' command.",
        "a": "no"
      },
      {
        "c": "Modify the Instances VPC subnet route table by adding a route back to the customer's on-premises environment.",
        "a": "yes"
      }
    ],
    "nt": "Enabling route propagation to the virtual private gateway (VGW) allows the routes learned from the customer's on-premises network via BGP over the Direct Connect connection to be automatically propagated to the VPC route tables. Modifying the VPC subnet route tables to add a specific route back to the on-premises environment ensures that return traffic from the EC2 instances can find its way back through the Direct Connect connection."
  },
  {
    "id": 1453,
    "q": "While creating a network in the VPC, which of the following is true of a NAT device?",
    "o": [
      {
        "c": "You have to administer the NAT Gateway Service provided by AW",
        "a": "no"
      },
      {
        "c": "You can choose to use any of the three kinds of NAT devices offered by AWS for special purposes.",
        "a": "no"
      },
      {
        "c": "You can use a NAT device to enable instances in a private subnet to connect to the Internet.",
        "a": "yes"
      },
      {
        "c": "You are recommended to use AWS NAT instances over NAT gateways, as the instances provide better availability and bandwidth.",
        "a": "no"
      }
    ],
    "nt": "A NAT (Network Address Translation) device, such as a NAT Gateway or a NAT instance, allows instances in a private subnet to initiate outbound connections to the internet or other AWS services, while preventing unsolicited inbound connections from the internet from reaching those instances. This is a fundamental use case for NAT devices within a VPC architecture."
  },
  {
    "id": 1454,
    "q": "Which of the following statements is NOT true about using Elastic IP Address (EIP) in EC2-Classic and EC2-VPC platforms?",
    "o": [
      {
        "c": "In the EC2-VPC platform, the Elastic IP Address (EIP) does not remain associated with the instance when you stop it.",
        "a": "yes"
      },
      {
        "c": "In the EC2-Classic platform, stopping the instance disassociates the Elastic IP Address (EIP) from it.",
        "a": "no"
      },
      {
        "c": "In the EC2-VPC platform, if you have attached a second network interface to an instance, when you disassociate the Elastic IP Address (EIP) from that instance, a new public IP address is not assigned to the instance automatically; you'll have to associate an EIP with it manually.",
        "a": "no"
      },
      {
        "c": "In the EC2-Classic platform, if you disassociate an Elastic IP Address (EIP) from the instance, the instance is automatically assigned a new public IP address within a few minutes.",
        "a": "no"
      }
    ],
    "nt": "In the EC2-VPC platform, when you stop an instance, any associated Elastic IP address (EIP) remains associated with the instance. This behavior is different from EC2-Classic, where stopping an instance disassociates the EIP. The statement claiming that the EIP does *not* remain associated in VPC upon stop is therefore incorrect."
  },
  {
    "id": 1455,
    "q": "A user has hosted an application on EC2 instances. The EC2 instances are configured with ELB and Auto Scaling. The application server session time out is 2 hours. The user wants to configure connection draining to ensure that all in-flight requests are supported by ELB even though the instance is being deregistered. What time out period should the user specify for connection draining?",
    "o": [
      {
        "c": "1 hour.",
        "a": "yes"
      },
      {
        "c": "30 minutes.",
        "a": "no"
      },
      {
        "c": "5 minutes.",
        "a": "no"
      },
      {
        "c": "2 hours.",
        "a": "no"
      }
    ],
    "nt": "Connection draining allows the load balancer to complete in-flight requests made to instances that are de-registering or unhealthy. The timeout value should be set based on the typical time it takes for a request to be processed. While the application session timeout is 2 hours, the individual request processing time is likely much shorter. A 1-hour timeout provides a significant buffer for most requests to complete without needing to match the full session timeout, balancing robustness with the need to eventually complete the de-registration process."
  },
  {
    "id": 1456,
    "q": "What does the following command do with respect to the Amazon EC2 security groups? ec2-create-group CreateSecurityGroup",
    "o": [
      {
        "c": "Groups the user created security groups in to a new group for easy access.",
        "a": "no"
      },
      {
        "c": "Creates a new security group for use with your account.",
        "a": "yes"
      },
      {
        "c": "Creates a new group inside the security group.",
        "a": "no"
      },
      {
        "c": "Creates a new rule inside the security group.",
        "a": "no"
      }
    ],
    "nt": "The `ec2-create-group` command (or the equivalent `CreateSecurityGroup` API action) is used to create a new security group within a user's VPC or for EC2-Classic. A security group acts as a virtual firewall for EC2 instances to control inbound and outbound traffic."
  },
  {
    "id": 1457,
    "q": "You are in the process of moving your friend's WordPress site onto AWS to try and save him some money, and you have told him that he should probably also move his domain name. He asks why he can't leave his domain name where it is and just have his infrastructure on AWS. What would be an incorrect response to his question?",
    "o": [
      {
        "c": "Route 53 offers low query latency for your end users.",
        "a": "no"
      },
      {
        "c": "Route 53 is designed to automatically answer queries from the optimal location depending on network conditions.",
        "a": "no"
      },
      {
        "c": "The globally distributed nature of AWS's DNS servers helps ensure a consistent ability to route your end users to your application.",
        "a": "no"
      },
      {
        "c": "Route 53 supports Domain Name System Security Extensions (DNSSEC).",
        "a": "yes"
      }
    ],
    "nt": "While Route 53 does support DNSSEC (Domain Name System Security Extensions), this is not a primary reason for migrating a domain name to Route 53 in the context of cost-saving and hosting a WordPress site. The other options describe core benefits of Route 53 related to performance, reliability, and global availability, which are more directly relevant to improving the user experience and reliability of a website. Stating that DNSSEC support is a key reason would be an incorrect or misleading emphasis for this specific scenario."
  },
  {
    "id": 1458,
    "q": "Which of the following are characteristics of a reserved instance? (Choose 3 answers)",
    "o": [
      {
        "c": "It can be migrated across Availability Zones.",
        "a": "yes"
      },
      {
        "c": "It is specific to an Amazon Machine Image (AMI).",
        "a": "no"
      },
      {
        "c": "It can be applied to instances launched by Auto Scaling.",
        "a": "no"
      },
      {
        "c": "It is specific to an instance Type.",
        "a": "yes"
      },
      {
        "c": "It can be used to lower Total Cost of Ownership (TCO) of a system.",
        "a": "yes"
      }
    ],
    "nt": "Reserved Instances (RIs) provide a significant discount (up to 75%) compared to On-Demand pricing and provide a capacity reservation when used in a specific Availability Zone. Regional RIs can be migrated across AZs within the same region. RIs are specific to an instance type (e.g., m5.large) and family (e.g., m5), not a specific AMI. They are a billing discount applied to running instances that match the RI attributes, which can be leveraged by instances launched via Auto Scaling if the attributes match. The primary purpose is to reduce the Total Cost of Ownership (TCO) for steady-state workloads."
  },
  {
    "id": 1459,
    "q": "A user has defined an AutoScaling termination policy to first delete the instance with the nearest billing hour. AutoScaling has launched 3 instances in the US-East-1A region and 2 instances in the US-East-1B region. One of the instances in the US-East-1B region is running nearest to the billing hour. Which instance will AutoScaling terminate first while executing the termination action?",
    "o": [
      {
        "c": "Random Instance from US-East-1A.",
        "a": "no"
      },
      {
        "c": "Instance with the nearest billing hour in US-East-1B.",
        "a": "no"
      },
      {
        "c": "Instance with the nearest billing hour in US-East-1A.",
        "a": "yes"
      },
      {
        "c": "Random instance from US-East-1B.",
        "a": "no"
      }
    ],
    "nt": "When Auto Scaling needs to terminate an instance, it first identifies the Availability Zone (AZ) with the most instances. If there are multiple AZs with the same number of instances, it then selects the instance based on the specified termination policy (in this case, the one nearest to the next billing hour). Here, US-East-1A has 3 instances, and US-East-1B has 2 instances. Therefore, Auto Scaling will first look within US-East-1A (the AZ with the most instances) and then apply the 'nearest billing hour' policy to the instances within *that AZ* to select the specific instance to terminate."
  },
  {
    "id": 1460,
    "q": "You have an environment that consists of a public subnet using Amazon VPC and 3 instances that are running in this subnet. These three instances can successfully communicate with other hosts on the Internet. You launch a fourth instance in the same subnet, using the same AMI and security group configuration you used for the others, but find that this instance cannot be accessed from the internet. What should you do to enable Internet access?",
    "o": [
      {
        "c": "Deploy a NAT instance into the public subnet.",
        "a": "no"
      },
      {
        "c": "Assign an Elastic IP address to the fourth instance.",
        "a": "yes"
      },
      {
        "c": "Configure a publically routable IP Address in the host OS of the fourth instance.",
        "a": "no"
      },
      {
        "c": "Modify the routing table for the public subnet.",
        "a": "no"
      }
    ],
    "nt": "In a default VPC, instances in a public subnet are automatically assigned a public IP address. However, in a non-default VPC, this behavior is controlled by the subnet's 'auto-assign public IP' setting. If this setting is disabled for the subnet, instances launched into it will not receive a public IP unless one is explicitly assigned. An Elastic IP (EIP) is a static, public IPv4 address that can be allocated to your AWS account and then associated with an instance, providing it with a persistent public IP address reachable from the internet, assuming the route table and security groups allow it."
  },
  {
    "id": 1461,
    "q": "What does the 'Server Side Encryption' option on Amazon S3 provide?",
    "o": [
      {
        "c": "It provides an encrypted virtual disk in the Cloud.",
        "a": "no"
      },
      {
        "c": "It doesn't exist for Amazon S3, but only for Amazon EC2.",
        "a": "no"
      },
      {
        "c": "It encrypts the files that you send to Amazon S3, on the server side.",
        "a": "yes"
      },
      {
        "c": "It allows to upload fi les using an SSL endpoint, for a secure transfer.",
        "a": "no"
      }
    ],
    "nt": "Amazon S3 Server-Side Encryption (SSE) is a feature that automatically encrypts data at the object level as it is written to S3 buckets and decrypts it when it is accessed. The encryption, key management, and decryption are handled entirely by AWS on the server side. There are different key management options for SSE, including SSE-S3 (AWS-managed keys), SSE-KMS (AWS Key Management Service), and SSE-C (customer-provided keys)."
  },
  {
    "id": 1462,
    "q": "What is a placement group?",
    "o": [
      {
        "c": "A collection of Auto Scaling groups in the same region.",
        "a": "no"
      },
      {
        "c": "A feature that enables EC2 instances to interact with each other via high bandwidth, low latency connections.",
        "a": "yes"
      },
      {
        "c": "A collection of authorized CloudFront edge locations for a distribution.",
        "a": "no"
      },
      {
        "c": "A collection of Elastic Load Balancers in the same Region or Availability Zone.",
        "a": "no"
      }
    ],
    "nt": "A placement group is a logical grouping of instances within a single Availability Zone. Placement groups are recommended for applications that benefit from low network latency, high network throughput, or both. There are three types: Cluster placement groups (for low latency and high throughput between instances), Spread placement groups (for critical instances that should be kept on distinct underlying hardware to reduce correlated failures), and Partition placement groups (for large distributed and replicated workloads like HDFS, HBase, and Cassandra)."
  },
  {
    "id": 1463,
    "q": "You are checking the workload on some of your General Purpose (SSD) and Provisioned IOPS (SSD) volumes and it seems that the I/O latency is higher than you require. You should probably check the [...] to make sure that your application is not trying to drive more IOPS than you have provisioned.",
    "o": [
      {
        "c": "amount of IOPS that are available.",
        "a": "no"
      },
      {
        "c": "acknowledgement from the storage subsystem.",
        "a": "no"
      },
      {
        "c": "average queue length.",
        "a": "yes"
      },
      {
        "c": "time it takes for the I/O operation to complete.",
        "a": "no"
      }
    ],
    "nt": "The average queue length is a key Amazon CloudWatch metric for EBS volumes. It represents the number of read and write operation requests waiting to be completed. If your application is driving more IOPS than the volume can support (e.g., exceeding the baseline IOPS for gp2 or the provisioned IOPS for io1/io2), the queue length will start to increase. A consistently high queue length indicates that the volume is the bottleneck, and I/O operations are waiting, leading to higher I/O latency. Checking this metric helps determine if you need to provision a volume with higher performance characteristics."
  },
  {
    "id": 1464,
    "q": "Within the IAM service a GROUP is regarded as a:",
    "o": [
      {
        "c": "A collection of AWS accounts.",
        "a": "no"
      },
      {
        "c": "It's the group of EC2 machines that gain t he permissions specified in the GROUP.",
        "a": "no"
      },
      {
        "c": "There's no GROUP in IAM, but only USERS and RESOURCES.",
        "a": "no"
      },
      {
        "c": "A collection of users.",
        "a": "yes"
      }
    ],
    "nt": "In AWS Identity and Access Management (IAM), a group is a collection of IAM users. Groups let you specify permissions for multiple users, which can make it easier to manage the permissions for those users. For example, you could have a group called 'Admins' and give that group the types of permissions that administrators typically need. Any user in that group automatically has the permissions that are assigned to the group."
  },
  {
    "id": 1465,
    "q": "Doug has created a VPC with CIDR 10.201.0.0/16 in his AWS account. In this VPC he has created a public subnet with CIDR block 10.201.31.0/24. While launching a new EC2 from the console, he is not able to assign the private IP address 10.201.31.6 to this instance. Which is the most likely reason for this issue?",
    "o": [
      {
        "c": "Private IP address 10.201.31.6 is blocked via ACLs in Amazon infrastructure as a part of platform security.",
        "a": "no"
      },
      {
        "c": "Private address IP 10.201.31.6 is currently assigned to another interface.",
        "a": "yes"
      },
      {
        "c": "Private IP address 10.201.31.6 is not part of the associated subnet's IP address range.",
        "a": "no"
      },
      {
        "c": "Private IP address 10.201.31.6 is reserved by Amazon for IP networking purposes.",
        "a": "no"
      }
    ],
    "nt": "Within a subnet, each private IP address must be unique. AWS reserves the first four IP addresses and the last IP address in each subnet's CIDR block. The address 10.201.31.6 is within the usable range for the subnet 10.201.31.0/24 (usable range: 10.201.31.4 - 10.201.31.254). The most likely reason for not being able to assign it is that it is already assigned to another network interface (ENI) within the same subnet. IP addresses, once assigned to a running instance or an ENI, cannot be assigned to another resource until they are released."
  },
  {
    "id": 1466,
    "q": "A user is planning to make a mobile game which can be played online or offline and will be hosted on EC2. The user wants to ensure that if someone breaks the highest score or they achieve some milestone they can inform all their colleagues through email. Which of the below mentioned AWS services helps achieve this goal?",
    "o": [
      {
        "c": "AWS Simple Workflow Service.",
        "a": "no"
      },
      {
        "c": "AWS Simple Email Service.",
        "a": "yes"
      },
      {
        "c": "Amazon Cognito.",
        "a": "no"
      },
      {
        "c": "AWS Simple Queue Service.",
        "a": "no"
      }
    ],
    "nt": "Amazon Simple Email Service (SES) is a cost-effective, flexible, and scalable email service that enables developers to send mail from within any application. It is the ideal service for sending transactional emails, such as score alerts or milestone notifications, directly from an EC2 instance or via the AWS SDKs integrated into the application backend."
  },
  {
    "id": 1467,
    "q": "Is creating a Read Replica of another Read Replica supported?",
    "o": [
      {
        "c": "Only in VPC.",
        "a": "no"
      },
      {
        "c": "Yes.",
        "a": "no"
      },
      {
        "c": "Only in certain regions.",
        "a": "no"
      },
      {
        "c": "No.",
        "a": "yes"
      }
    ],
    "nt": "Creating a read replica from another read replica (cascading replication) is not supported in Amazon RDS. All read replicas must be created directly from the source DB instance. This architecture simplifies the replication topology and helps ensure data consistency and reduce replication lag."
  },
  {
    "id": 1468,
    "q": "Which of the following is NOT a characteristic of Amazon Elastic Compute Cloud (Amazon EC2)?",
    "o": [
      {
        "c": "It can be used to launch as many or as few virtual servers as you need.",
        "a": "no"
      },
      {
        "c": "It increases the need to forecast traffic by providing dynamic IP addresses for static cloud computing.",
        "a": "yes"
      },
      {
        "c": "It eliminates your need to invest in hardware up front, so you can develop and deploy applications faster.",
        "a": "no"
      },
      {
        "c": "It offers scalable computing capacity in the Amazon Web Services (AWS) cloud.",
        "a": "no"
      }
    ],
    "nt": "A core benefit of Amazon EC2 and cloud computing, in general, is the reduction or elimination of the need for long-term capacity planning and traffic forecasting. EC2 provides elastic, on-demand capacity that can be scaled up or down automatically based on actual demand, which directly *reduces* the need for precise traffic forecasting, contrary to what the incorrect statement suggests."
  },
  {
    "id": 1469,
    "q": "A user has launched one EC2 instance in the US East region and one in the US West region. The user has launched an RDS instance in the US East region. How can the user configure access from both the EC2 instances to RDS?",
    "o": [
      {
        "c": "It is not possible to access RDS of the US East region from the US West region.",
        "a": "no"
      },
      {
        "c": "Configure the US West region's security group to allow a request from the US East region's instance and configure the RDS security group's ingress rule for the US East EC2 group.",
        "a": "no"
      },
      {
        "c": "Configure the security group of the US East region to allow traffic from the US West region's instance and configure the RDS security group's ingress rule for the US East EC2 group.",
        "a": "yes"
      },
      {
        "c": "Configure the security group of both instances in the ingress rule of the RDS security group.",
        "a": "no"
      }
    ],
    "nt": "RDS security groups are region-specific and control access to the RDS instance. To allow an EC2 instance in a different region (US West) to access an RDS instance in the US East region, you must configure the RDS security group's ingress rules to allow inbound traffic from the EC2 instance's IP address or its security group (if it's in the same region as the RDS instance). Since the instances are in different regions, you typically cannot reference the US West instance's security group directly in the US East RDS security group rule. Therefore, the most straightforward method is to authorize the specific public IP address (or CIDR range) of the US West EC2 instance in the RDS security group's inbound rules. The correct option implies this by stating to configure the RDS security group for the US East EC2 group (which handles the local instance) and also to allow traffic originating from the US West instance's location, which would be done by its IP address."
  },
  {
    "id": 1470,
    "q": "What happens to the I/O operations while you take a database snapshot?",
    "o": [
      {
        "c": "I/O operations to the database are suspended for an hour while the backup is in progress.",
        "a": "no"
      },
      {
        "c": "I/O operations to the database are sent to a Replica (if available) for a few minutes while the backup is in progress.",
        "a": "no"
      },
      {
        "c": "I/O operations will be functioning normally.",
        "a": "no"
      },
      {
        "c": "I/O operations to the database are suspended for a few minutes while the backup is in progress.",
        "a": "yes"
      }
    ],
    "nt": "During the backup window for a DB snapshot (initiated manually), I/O activity on your DB instance may be briefly suspended while the snapshot process initializes. This I/O suspension typically lasts for a few minutes for single-AZ deployments. For Multi-AZ deployments, this suspension is avoided because the backup is taken from the standby replica. It's important to note that this suspension is different from the brief I/O suspension that occurs during automated backups for single-AZ instances."
  },
  {
    "id": 1471,
    "q": "When an EC2 EBS-backed (EBS root) instance is stopped, what happens to the data on any ephemeral store volumes?",
    "o": [
      {
        "c": "Data is automatically saved in an EBS volume.",
        "a": "no"
      },
      {
        "c": "Data is unavailable until the instance is restarted.",
        "a": "yes"
      },
      {
        "c": "Data will be deleted and will no longer be accessible.",
        "a": "no"
      },
      {
        "c": "Data is automatically saved as an EBS snapshot.",
        "a": "no"
      }
    ],
    "nt": "Instance store (ephemeral storage) volumes provide temporary block-level storage for an instance. The data on an instance store volume persists only during the lifetime of its associated instance. When an instance is stopped (not terminated), the data on instance store volumes becomes unavailable because the instance is shut down on the host. However, if the instance is subsequently started again, AWS might place it on a new host, and any data on the instance store volumes from the previous host would be lost. If the instance is restarted on the *same host* (which can happen but is not guaranteed), the data might still be present, but this behavior should not be relied upon. The safest design is to consider instance store data as non-persistent across stop/start cycles."
  },
  {
    "id": 1472,
    "q": "[...] is a durable, block-level storage volume that you can attach to a single, running Amazon EC2 instance.",
    "o": [
      {
        "c": "Amazon S3.",
        "a": "no"
      },
      {
        "c": "Amazon EBS.",
        "a": "yes"
      },
      {
        "c": "None of these.",
        "a": "no"
      },
      {
        "c": "All of these.",
        "a": "no"
      }
    ],
    "nt": "Amazon Elastic Block Store (EBS) provides durable, block-level storage volumes that can be attached to a single, running Amazon EC2 instance in the same Availability Zone. EBS volumes are persistent, independent of the life of an instance, and can be used as a primary storage device for data that requires frequent updates."
  },
  {
    "id": 1473,
    "q": "A favored client needs you to quickly deploy a database that is a relational database service with minimal administration as he wants to spend the least amount of time administering it. Which database would be the best option?",
    "o": [
      {
        "c": "Amazon SimpleDB.",
        "a": "no"
      },
      {
        "c": "Your choice of relational AMIs on Amazon EC2 and EB.",
        "a": "no"
      },
      {
        "c": "Amazon RDS.",
        "a": "yes"
      },
      {
        "c": "Amazon Redshift.",
        "a": "no"
      }
    ],
    "nt": "Amazon Relational Database Service (RDS) is a managed service that simplifies the setup, operation, and scaling of a relational database in the cloud. It provides cost-efficient and resizable capacity while automating time-consuming administration tasks such as hardware provisioning, database setup, patching, and backups. This makes it the ideal choice for clients who want a relational database with minimal administrative overhead."
  },
  {
    "id": 1474,
    "q": "You have a number of image files to encode. In an Amazon SQS worker queue, you create an Amazon SQS message for each file specifying the command (jpeg-encode) and the location of the file in Amazon S3. Which of the following statements best describes the functionality of Amazon SQS?",
    "o": [
      {
        "c": "Amazon SQS is a distributed queuing system that is optimized for horizontal scalability, not for single-threaded sending or receiving speeds.",
        "a": "yes"
      },
      {
        "c": "Amazon SQS is for single-threaded sending or receiving speeds.",
        "a": "no"
      },
      {
        "c": "Amazon SQS is a non-distributed queuing system.",
        "a": "no"
      },
      {
        "c": "Amazon SQS is a distributed queuing system that is optimized for vertical scalability and for single-threaded sending or receiving speeds.",
        "a": "no"
      }
    ],
    "nt": "Amazon Simple Queue Service (SQS) is a fully managed message queuing service that enables you to decouple and scale microservices, distributed systems, and serverless applications. SQS is a distributed system, and its design is optimized for horizontal scalability, allowing many producers and consumers to interact with the queue simultaneously. It is not optimized for the maximum single-threaded sending or receiving speed of a single client, but rather for the overall throughput and reliability of the system across many clients."
  },
  {
    "id": 1475,
    "q": "While creating an Amazon RDS DB, your first task is to set up a DB [...] that controls what IP addresses or EC2 instances have access to your DB Instance.",
    "o": [
      {
        "c": "Security Pool.",
        "a": "no"
      },
      {
        "c": "Secure Zone.",
        "a": "no"
      },
      {
        "c": "Security Token Pool.",
        "a": "no"
      },
      {
        "c": "Security Group.",
        "a": "yes"
      }
    ],
    "nt": "A DB Security Group acts as a virtual firewall that controls network access to your Amazon RDS DB instance. You can specify which IP ranges (CIDR blocks) or which Amazon EC2 security groups are allowed to connect to your DB instance. This is a fundamental step in securing an RDS deployment."
  },
  {
    "id": 1476,
    "q": "After launching an instance that you intend to serve as a NAT (Network Address Translation) device in a public subnet you modify your route tables to have the NAT device be the target of internet bound traffic of your private subnet. When you try and make an outbound connection to the internet from an instance in the private subnet, you are not successful. Which of the following steps could resolve the issue?",
    "o": [
      {
        "c": "Disabling the Source/Destination Check attribute on the NAT instance.",
        "a": "yes"
      },
      {
        "c": "Attaching an Elastic IP address to the instance in the private subnet.",
        "a": "no"
      },
      {
        "c": "Attaching a second Elastic Network Interface (EN I) to the NAT instance, and placing it in the private subnet.",
        "a": "no"
      },
      {
        "c": "Attaching a second Elastic Network Interface (ENI) to the instance in the private subnet, and placing it in the public subnet.",
        "a": "no"
      }
    ],
    "nt": "Every EC2 instance performs source/destination checks by default, meaning the instance must be the source or destination of any traffic it sends or receives. A NAT instance, however, needs to handle traffic for other instances (those in the private subnet). Therefore, you must disable source/destination checking on the NAT instance so it can receive traffic addressed to other destinations and forward that traffic, and vice-versa."
  },
  {
    "id": 1477,
    "q": "Which of the following would you use to list your AWS Import/Export jobs?",
    "o": [
      {
        "c": "Amazon RDS.",
        "a": "no"
      },
      {
        "c": "AWS Import/Export Web Service Tool.",
        "a": "no"
      },
      {
        "c": "Amazon S3 REST API.",
        "a": "yes"
      },
      {
        "c": "AWS Elastic Beanstalk.",
        "a": "no"
      }
    ],
    "nt": "AWS Import/Export jobs, which involve shipping physical storage devices to AWS to transfer large amounts of data into or out of Amazon S3 or Amazon EBS, are managed using the Amazon S3 REST API. You can use the API to create, list, and track the status of these jobs. The legacy AWS Import/Export Disk tool has been largely superseded by AWS Snowball, but the principle of using S3 APIs for job management for the original service remains correct."
  },
  {
    "id": 1478,
    "q": "Company B is launching a new game app for mobile devices. Users will log into the game using their existing social media account to streamline data capture. Company B would like to directly save player data and scoring information from the mobile app to a DynamoDB table named Score Data. When a user saves their game, the progress data will be stored to the Game State S3 bucket. What is the best approach for storing data to DynamoDB and S3?",
    "o": [
      {
        "c": "Use an EC2 Instance that is launched with an EC2 role providing access to the Score Data DynamoDB table and the GameState S3 bucket that communicates with the mobile app via web services.",
        "a": "no"
      },
      {
        "c": "Use temporary security credentials that assume a role providing access to the Score Data DynamoDB table and the Game State S3 bucket using web identity federation.",
        "a": "yes"
      },
      {
        "c": "Use Login with Amazon allowing users to sign in with an Amazon account providing the mobile app with access to the Score Data DynamoDB table and the Game State S3 bucket.",
        "a": "no"
      },
      {
        "c": "Use an IAM user with access credentials assigned a role providing access to the Score Data DynamoDB table and the Game State S3 bucket for distribution with the mobile app.",
        "a": "no"
      }
    ],
    "nt": "Web Identity Federation allows users to authenticate with a well-known identity provider (like Amazon, Facebook, Google) and then exchange that authentication for temporary AWS security credentials. These temporary credentials are associated with an IAM role that has precisely defined permissions (e.g., write to a specific DynamoDB table and S3 bucket). This is the recommended and secure approach for mobile applications because it avoids embedding long-term AWS credentials (like IAM user keys) in the application, which is a severe security risk. The temporary credentials are short-lived and scoped to the permissions defined by the role."
  },
  {
    "id": 1479,
    "q": "If your DB instance runs out of storage space or file system resources, its status will change to [...] and your DB Instance will no longer be available.",
    "o": [
      {
        "c": "storage-overflow.",
        "a": "no"
      },
      {
        "c": "storage-full.",
        "a": "yes"
      },
      {
        "c": "storage-exceed.",
        "a": "no"
      },
      {
        "c": "storage-overage.",
        "a": "no"
      }
    ],
    "nt": "When an Amazon RDS DB instance exhausts its allocated storage, its status will change to 'storage-full', and it will become unavailable. I/O operations will be suspended to prevent further write activity. To resolve this, you must modify the DB instance to allocate more storage, which will require an outage. It is crucial to monitor storage usage via CloudWatch and set up alarms to proactively add storage before this condition occurs."
  },
  {
    "id": 1480,
    "q": "Your application is using an ELB in front of an Auto Scaling group of web/application servers deployed across two AZs and a Multi-AZ RDS Instance for data persistence. The database CPU is often above 80% usage and 90% of I/O operations on the database are reads. To improve performance you recently added a single-node Memcached ElastiCache Cluster to cache frequent DB query results. In the next weeks the overall workload is expected to grow by 30%. Do you need to change anything in the architecture to maintain the high availability of the application with the anticipated additional load? Why?",
    "o": [
      {
        "c": "Yes, you should deploy two Memcached ElastiCache Clusters in different AZs because the RDS instance will not be able to handle the load if the cache node fails.",
        "a": "yes"
      },
      {
        "c": "No, if the cache node fails you can always get the same data from the DB without having any availability impact.",
        "a": "no"
      },
      {
        "c": "No, if the cache node fails the automated ElastiCache node recovery feature will prevent any availability impact.",
        "a": "no"
      },
      {
        "c": "Yes, you should deploy the Memcached ElastiCache Cluster with two nodes in the same AZ as the RDS DB master instance to handle the load if one cache node fails.",
        "a": "no"
      }
    ],
    "nt": "A single-node ElastiCache cluster does not provide high availability. If that single cache node fails, all cached data is lost, and the application will be forced to serve all read requests directly from the RDS instance. Given that the RDS instance is already under high load (CPU often above 80%), a sudden 100% increase in read load (due to cache failure) would likely overwhelm the database, causing severe performance degradation or unavailability. To maintain high availability and performance under the increased load and potential failures, you should deploy a Multi-AZ ElastiCache cluster (for Redis) or multiple nodes across different Availability Zones (for Memcached, which is a distributed, non-persistent cache). This ensures that if a node fails, the others can continue to serve requests, preventing a cascade failure onto the database."
  },
  {
    "id": 1481,
    "q": "How many Elastic IP by default in Amazon Account?",
    "o": [
      {
        "c": "1 Elastic IP.",
        "a": "no"
      },
      {
        "c": "3 Elastic IP.",
        "a": "no"
      },
      {
        "c": "5 Elastic IP.",
        "a": "no"
      },
      {
        "c": "0 Elastic IP.",
        "a": "yes"
      }
    ],
    "nt": "By default, all AWS accounts are limited to 5 Elastic IP addresses per region. However, the question asks how many Elastic IPs you have 'by default' in an account. The correct interpretation is that a new account starts with zero allocated Elastic IPs. You can allocate up to 5, but you begin with none. Furthermore, you are only charged for Elastic IP addresses if they are not associated with a running instance."
  },
  {
    "id": 1482,
    "q": "What would be the best way to retrieve the public IP address of your EC2 instance using the CLI?",
    "o": [
      {
        "c": "Using tags.",
        "a": "no"
      },
      {
        "c": "Using traceroute.",
        "a": "no"
      },
      {
        "c": "Using ipconfig.",
        "a": "no"
      },
      {
        "c": "Using instance metadata.",
        "a": "yes"
      }
    ],
    "nt": "The Instance Metadata Service (IMDS) provides a secure way to access information about an EC2 instance from within the instance itself. By querying a specific URL (http://169.254.169.254/latest/meta-data/) from within the instance, you can retrieve various instance attributes, including its public IP address (at the path /latest/meta-data/public-ipv4). This is the most reliable and programmatic way for an application or script running on the instance to discover its own public IP address using the CLI (e.g., with `curl`)."
  },
  {
    "id": 1483,
    "q": "A company is building a two-tier web application to serve dynamic transaction-based content. The data tier is leveraging an Online Transactional Processing (OLTP) database. What services should you leverage to enable an elastic and scalable web tier?",
    "o": [
      {
        "c": "Elastic Load Balancing, Amazon EC2, and Auto Scaling.",
        "a": "yes"
      },
      {
        "c": "Elastic Load Balancing, Amazon RDS with Multi-AZ, and Amazon S3.",
        "a": "no"
      },
      {
        "c": "Amazon RDS with Multi-AZ and Auto Scaling.",
        "a": "no"
      },
      {
        "c": "Amazon EC2, Amazon DynamoDB, and Amazon S3.",
        "a": "no"
      }
    ],
    "nt": "To create an elastic and scalable web tier for a dynamic application, the core AWS services are: Elastic Load Balancing (ELB) to distribute incoming traffic across multiple targets, Amazon EC2 to provide the virtual servers that run the web application, and Auto Scaling to automatically add or remove EC2 instances based on demand (e.g., CPU utilization, network traffic). This combination ensures the web tier can handle fluctuating loads efficiently and cost-effectively."
  },
  {
    "id": 1484,
    "q": "You are designing a connectivity solution between on-premises infrastructure and Amazon VPC. Your servers on-premises will be communicating with your VPC instances. You will be establishing IPSec tunnels over the internet. You will be using VPN gateways and terminating the IPsec tunnels on AWS supported customer gateways. Which of the following objectives would you achieve by implementing an IPSec tunnel as outlined above? (Choose 4 answers)",
    "o": [
      {
        "c": "End-to-end protection of data in transit.",
        "a": "no"
      },
      {
        "c": "End-to-end Identity authentication.",
        "a": "no"
      },
      {
        "c": "Data encryption across the Internet.",
        "a": "yes"
      },
      {
        "c": "Protection of data in transit over the Internet.",
        "a": "yes"
      },
      {
        "c": "Peer identity authentication between VPN gateway and customer gateway.",
        "a": "yes"
      },
      {
        "c": "Data integrity protection across the Internet.",
        "a": "yes"
      }
    ],
    "nt": "An IPSec VPN connection established between an on-premises customer gateway and an AWS VPN Gateway provides several key security benefits for the portion of the path that it covers (the internet segment): It encrypts the data packets, ensuring confidentiality as they traverse the public internet. It provides data integrity protection, ensuring that packets have not been altered in transit. It includes peer authentication, which verifies the identity of both the AWS VPN Gateway and the on-premises customer gateway before establishing the tunnel. It protects the data specifically while it is in transit over the internet. It does not, however, provide end-to-end protection (e.g., from the on-premises server to the VPC instance's operating system) or end-to-end identity authentication beyond the gateway peers."
  },
  {
    "id": 1485,
    "q": "You have been storing massive amounts of data on Amazon Glacier for the past 2 years and now start to wonder if there are any limitations on this. What is the correct answer to your question?",
    "o": [
      {
        "c": "The total volume of data is limited but the number of archives you can store are unlimited.",
        "a": "no"
      },
      {
        "c": "The total volume of data is unlimited but the number of archives you can store are limited.",
        "a": "no"
      },
      {
        "c": "The total volume of data and number of archives you can store are unlimited.",
        "a": "yes"
      },
      {
        "c": "The total volume of data is limited and the number of archives you can store are limited.",
        "a": "no"
      }
    ],
    "nt": "Amazon S3 Glacier (and its successor, S3 Glacier Flexible Retrieval) is designed for long-term, durable storage with very low costs. A key characteristic is its virtually unlimited scalability. There is no practical limit on the total amount of data (volume) you can store or the number of individual archives (objects) you can create within a vault. You pay only for the storage you use."
  },
  {
    "id": 1486,
    "q": "How are the EBS snapshots saved on Amazon S3?",
    "o": [
      {
        "c": "Exponentially.",
        "a": "no"
      },
      {
        "c": "Incrementally.",
        "a": "yes"
      },
      {
        "c": "EBS snapshots are not stored in the Amazon S3.",
        "a": "no"
      },
      {
        "c": "Decrementally.",
        "a": "no"
      }
    ],
    "nt": "EBS snapshots are stored incrementally in Amazon S3 (though not directly visible in a standard S3 bucket). This means that only the blocks on the device that have changed since your last snapshot are saved. This incremental approach minimizes the storage space required and reduces the time and cost of creating subsequent snapshots. When you delete a snapshot, only the data unique to that snapshot is removed."
  },
  {
    "id": 1487,
    "q": "An online gaming site asked you if you can deploy a database that is a fast, highly scalable NoSQL database service in AWS for a new site that he wants to build. Which database should you recommend?",
    "o": [
      {
        "c": "Amazon DynamoDB.",
        "a": "yes"
      },
      {
        "c": "Amazon RDS.",
        "a": "no"
      },
      {
        "c": "Amazon Redshift.",
        "a": "no"
      },
      {
        "c": "Amazon SimpleDB.",
        "a": "no"
      }
    ],
    "nt": "Amazon DynamoDB is a fully managed NoSQL database service that provides fast and predictable performance with seamless scalability. It is an excellent choice for gaming applications that require low-latency data access, can benefit from a flexible schema, and need to handle massive scale in terms of both storage and request traffic. DynamoDB automatically distributes data and traffic for tables over a sufficient number of servers to handle the request capacity specified by the customer."
  },
  {
    "id": 1488,
    "q": "You have three Amazon EC2 instances with Elastic IP addresses in the US East (Virginia) region, and you want to distribute requests across all three IPs evenly for users for whom US East (Virginia) is the appropriate region. How many EC2 instances would be sufficient to distribute requests in other regions?",
    "o": [
      {
        "c": "3.",
        "a": "no"
      },
      {
        "c": "9.",
        "a": "no"
      },
      {
        "c": "2.",
        "a": "no"
      },
      {
        "c": "1.",
        "a": "yes"
      }
    ],
    "nt": "This question is about using Amazon Route 53 latency-based routing. Latency-based routing directs traffic to the region that provides the best latency for the end user. You don't need to have an equal number of resources in every region. For users for whom a different region (e.g., Europe or Asia) provides the lowest latency, Route 53 would route them to an endpoint in that region. A single EC2 instance in another region is sufficient to serve as the endpoint for all users for whom that region is the lowest-latency option. The load on that single instance can be managed by its own scaling policies if necessary."
  },
  {
    "id": 1489,
    "q": "You are working with a customer who is using Chef configuration management in their data center. Which service is designed to let the customer leverage existing Chef recipes in AWS?",
    "o": [
      {
        "c": "Amazon Simple Workflow Service.",
        "a": "no"
      },
      {
        "c": "AWS Elastic Beanstalk.",
        "a": "no"
      },
      {
        "c": "AWS CloudFormation.",
        "a": "no"
      },
      {
        "c": "AWS OpsWorks.",
        "a": "yes"
      }
    ],
    "nt": "AWS OpsWorks is a configuration management service that provides managed instances of Chef and Puppet. Chef and Puppet are automation platforms that allow you to use code to automate the configurations of your servers. OpsWorks lets you use Chef recipes (and Puppet manifests) to automate how servers are configured, deployed, and managed across your Amazon EC2 instances or on-premises compute environments."
  },
  {
    "id": 1490,
    "q": "You are implementing a URL whitelisting system for a company that wants to restrict outbound HTTPS connections to specific domains from their EC2-hosted applications. You deploy a single EC2 instance running proxy software and configure it to accept traffic from all subnets and EC2 instances in the VPC. You configure the proxy to only pass through traffic to domains that you define in its whitelist configuration. You have a nightly maintenance window of 10 minutes where all instances fetch new software updates. Each update is about 200MB in size and there are 500 instances in the VPC that routinely fetch updates. After a few days you notice that some machines are failing to successfully download some, but not all of their updates within the maintenance window. The download URLs used for these updates are correctly listed in the proxy's whitelist configuration and you are able to access them manually using a web browser on the instances. What might be happening? (Choose 2 answers)",
    "o": [
      {
        "c": "You are running the proxy on an undersized EC2 instance type so network throughput is not sufficient for all instances to download their updates in time.",
        "a": "yes"
      },
      {
        "c": "You are running the proxy on a sufficiently-sized EC2 instance in a private subnet and its network throughput is being throttled by a NAT running on an undersized EC2 instance.",
        "a": "yes"
      },
      {
        "c": "The route table for the subnets containing the affected EC2 instances is not configured to direct network traffic for the software update locations to the proxy.",
        "a": "no"
      },
      {
        "c": "You have not allocated enough storage to the EC2 instance running the proxy so the network buffer is filling up, causing some requests to fail.",
        "a": "no"
      },
      {
        "c": "You are running the proxy in a public subnet but have not allocated enough EIPs to support the needed network throughput through the Internet Gateway (IGW).",
        "a": "no"
      }
    ],
    "nt": "The proxy instance itself might be undersized, creating a bottleneck as 500 instances simultaneously try to download 200MB files through it. Different EC2 instance types have different network performance characteristics, and a smaller instance might not provide enough aggregate throughput. Additionally, if the proxy is in a private subnet, it needs a NAT Gateway (or NAT instance) to reach the internet. If that NAT device is undersized, it becomes the bottleneck, throttling the proxy's outbound traffic even if the proxy instance itself is adequately sized."
  },
  {
    "id": 1491,
    "q": "You are playing around with setting up stacks using JSON templates in CloudFormation to try and understand them a little better. You have set up about 5 or 6 but now start to wonder if you are being charged for these stacks. What is AWS's billing policy regarding stack resources?",
    "o": [
      {
        "c": "You are not charged for the stack resources if they are not taking any traffic.",
        "a": "no"
      },
      {
        "c": "You are charged for the stack resources for the time they were operating (even if you deleted the stack right away).",
        "a": "yes"
      },
      {
        "c": "You are charged for the stack resources for the time they were operating (but not if you deleted the stack within 60 minutes).",
        "a": "no"
      },
      {
        "c": "You are charged for the stack resources for the time they were operating (but not if you deleted the stack within 30 minutes).",
        "a": "no"
      }
    ],
    "nt": "AWS CloudFormation itself is a free service. However, you are charged for the AWS resources (like EC2 instances, RDS databases, S3 storage, etc.) that CloudFormation creates and manages as part of your stacks. Billing for these underlying resources is based on their actual usage time, from the moment they are created until the moment they are terminated. Deleting a CloudFormation stack terminates these resources, but you are still billed for the time they were running."
  },
  {
    "id": 1492,
    "q": "What does Amazon Cloud Formation provide?",
    "o": [
      {
        "c": "The ability to setup Autoscaling for Amazon EC2 instances.",
        "a": "no"
      },
      {
        "c": "None of these.",
        "a": "no"
      },
      {
        "c": "A templated resource creation for Amazon Web Services.",
        "a": "yes"
      },
      {
        "c": "A template to map network resources for Amazon Web Services.",
        "a": "no"
      }
    ],
    "nt": "AWS CloudFormation provides a common language for you to model and provision AWS and third-party application resources in your cloud environment. You use a template (written in JSON or YAML) to describe all the AWS resources you need (like EC2 instances, RDS DB instances, S3 buckets, etc.), and CloudFormation takes care of provisioning and configuring those resources for you. It automates and simplifies infrastructure management, ensuring consistent and repeatable deployments."
  },
  {
    "id": 1493,
    "q": "You are signed in as root user on your account but there is an Amazon S3 bucket under your account that you cannot access. What is a possible reason for this?",
    "o": [
      {
        "c": "An IAM user assigned a bucket policy to an Amazon S3 bucket and didn't specify the root user as a principal",
        "a": "yes"
      },
      {
        "c": "The S3 bucket is full.",
        "a": "no"
      },
      {
        "c": "The S3 bucket has reached the maximum number of objects allowed.",
        "a": "no"
      },
      {
        "c": "You are in the wrong Availability Zone.",
        "a": "no"
      }
    ],
    "nt": "S3 bucket policies are powerful, resource-based JSON policies that define which principals (users, accounts, services) are allowed or denied access to the bucket and its objects. Even the root user of the AWS account that owns the bucket can be explicitly denied access by a bucket policy if the policy's conditions or explicit 'Deny' statements override the root user's inherent permissions. S3 permissions are a union of multiple policy types (IAM policies, bucket policies, ACLs), and an explicit 'Deny' in any of them overrides any 'Allow'."
  },
  {
    "id": 1494,
    "q": "When creation of an EBS snapshot is initiated, but not completed, the EBS volume?",
    "o": [
      {
        "c": "Can be used while the snapshot is in progress.",
        "a": "no"
      },
      {
        "c": "Cannot be detached or attached to an EC2 instance until the snapshot completes.",
        "a": "no"
      },
      {
        "c": "Can be used in read-only mode while the snapshot is in progress.",
        "a": "no"
      },
      {
        "c": "Cannot be used until the snapshot completes.",
        "a": "yes"
      }
    ],
    "nt": "This statement is incorrect and describes the opposite of the actual behavior. In reality, you can continue to use an EBS volume (read and write data) while a snapshot is in progress. The snapshot captures a point-in-time state of the volume, and I/O operations to the volume are not suspended. However, for consistent snapshots, it's best practice to pause file systems or use other methods to ensure data integrity, but the volume itself remains fully usable."
  },
  {
    "id": 1495,
    "q": "What does Amazon SES stand for?",
    "o": [
      {
        "c": "Simple Elastic Server.",
        "a": "no"
      },
      {
        "c": "Simple Email Service.",
        "a": "yes"
      },
      {
        "c": "Software Email Solution.",
        "a": "no"
      },
      {
        "c": "Software Enabled Server.",
        "a": "no"
      }
    ],
    "nt": "Amazon SES stands for Simple Email Service. It is a cost-effective, flexible, and scalable email service that enables developers to send mail from within any application. It is commonly used for sending transactional emails (like order confirmations, password resets) and marketing communications."
  },
  {
    "id": 1496,
    "q": "You receive a bill from AWS but are confused because you see you are incurring different costs for the exact same storage size in different regions on Amazon S3. You ask AWS why this is so. What response would you expect to receive from AWS?",
    "o": [
      {
        "c": "We charge less in different time zones.",
        "a": "no"
      },
      {
        "c": "We charge less where our costs are less.",
        "a": "yes"
      },
      {
        "c": "This will balance out next bill.",
        "a": "no"
      },
      {
        "c": "It must be a mistake.",
        "a": "no"
      }
    ],
    "nt": "AWS pricing can vary by region. This is because the underlying costs of power, real estate, and other operational expenses differ across geographic locations. AWS passes these cost efficiencies (or lack thereof) on to the customer. Therefore, storing the same amount of data in the US East (N. Virginia) region might be cheaper than storing it in the South America (So Paulo) region due to these regional cost differences."
  },
  {
    "id": 1497,
    "q": "Disabling automated backups [...] disable the point-in-time recovery.",
    "o": [
      {
        "c": "if configured to can.",
        "a": "no"
      },
      {
        "c": "will never.",
        "a": "no"
      },
      {
        "c": "will.",
        "a": "yes"
      }
    ],
    "nt": "Point-in-time recovery (PITR) for Amazon RDS is a feature that automatically backs up your DB instance transaction logs, allowing you to restore your database to any specific second during the retention period, up to the last five minutes. This feature is dependent on the automated backup system. If you disable automated backups, you also disable the ability to perform point-in-time recovery, as the necessary transaction logs are no longer being captured and stored."
  },
  {
    "id": 1498,
    "q": "A user has launched a large EBS backed EC2 instance in the US-East-1a region. The user wants to achieve Disaster Recovery (DR) for that instance by creating another small instance in Europe. How can the user achieve DR?",
    "o": [
      {
        "c": "Copy the instance from the US East region to the EU region.",
        "a": "no"
      },
      {
        "c": "Use the 'Launch More like this' option to copy the instance from one region to another.",
        "a": "no"
      },
      {
        "c": "Copy the running instance using the 'Instance Copy' command to the EU region.",
        "a": "no"
      },
      {
        "c": "Create an AMI of the instance and copy the AMI to the EU region. Then launch the instance from the EU AMI.",
        "a": "yes"
      }
    ],
    "nt": "The primary method to replicate an EC2 instance to a different AWS region is by creating an Amazon Machine Image (AMI) from the source instance. An AMI is a template that contains the software configuration (operating system, application server, and applications) required to launch an instance. Once the AMI is created in the source region, you can copy it to the destination region (e.g., Europe). After the AMI copy is complete, you can launch a new instance (which can be a different instance type, like a smaller one) from that AMI in the destination region."
  },
  {
    "id": 1499,
    "q": "How many relational database engines does RDS currently support?",
    "o": [
      {
        "c": "Three: MySQL, Oracle and Microsoft SQL Server.",
        "a": "no"
      },
      {
        "c": "Just two: MySQL and Oracle.",
        "a": "no"
      },
      {
        "c": "Five: MySQL, PostgreSQL, MongoDB, Cassandra and SQLite.",
        "a": "no"
      },
      {
        "c": "Eight: Amazon Aurora PostgreSQL-Compatible Edition, Amazon Aurora MySQL-Compatible Edition, RDS for PostgreSQL, RDS for MySQL, RDS for MariaDB, RDS for SQL Server, RDS for Oracle, and RDS for Db2.",
        "a": "yes"
      }
    ],
    "nt": "Amazon RDS supports a wide range of database engines. As of the knowledge cutoff, it supports eight: Amazon Aurora (with both MySQL and PostgreSQL compatibility), PostgreSQL, MySQL, MariaDB, Oracle Database, Microsoft SQL Server, and Db2. It's important to note that RDS is a relational database service, so it does not support non-relational databases like MongoDB or Cassandra (those are offered through other AWS services like DocumentDB and Keyspaces)."
  },
  {
    "id": 1500,
    "q": "Are you able to integrate a multi-factor token service with the AWS Platform?",
    "o": [
      {
        "c": "Yes, you can integrate private multi-factor token devices to authenticate users to the AWS platform.",
        "a": "no"
      },
      {
        "c": "No, you cannot integrate multi-factor token devices with the AWS platform.",
        "a": "no"
      },
      {
        "c": "Yes, using the AWS multi-factor token devices to authenticate users on the AWS platform.",
        "a": "yes"
      }
    ],
    "nt": "AWS provides its own Multi-Factor Authentication (MFA) service that can be used to add an extra layer of protection to your AWS account and users. AWS MFA supports various virtual and hardware MFA devices, including virtual MFA applications (like Google Authenticator, Authy, etc.), Universal 2nd Factor (U2F) security keys, and other hardware MFA devices. These can be assigned to the AWS account root user and to individual IAM users to require a time-based one-time password (TOTP) in addition to their regular password when signing in to the AWS Management Console or making API calls."
  }
]